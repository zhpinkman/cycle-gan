{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cycleGAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDQvblfwHjvx"
      },
      "source": [
        "Import the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VZFgu4cXI7z",
        "outputId": "0be0daf0-35b9-428f-a588-07e416b0107f"
      },
      "source": [
        "!pip install albumentations==0.4.6"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: albumentations==0.4.6 in /usr/local/lib/python3.7/dist-packages (0.4.6)\n",
            "Requirement already satisfied: imgaug>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.19.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (3.13)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (4.1.2.30)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.4.1)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.4.1)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.7.1)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (0.16.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (3.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (7.1.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2.5.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.8.1)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (4.4.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "namOCN8_HwEz"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import sys\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from tqdm.notebook import tqdm\n",
        "from torchvision.utils import save_image\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import random, os\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SMPuFoAXRcR"
      },
      "source": [
        "### Discriminator Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAblsGeR3FYH"
      },
      "source": [
        "In this part of the notebook the blocks which are the building blocks of the generator and discriminator modules are defined. These blocks are defined so that they can down sample and also up sample the information which are fed to them. These informations are indeed the photos and random data also known az Z vector. The discriminator module, the input vector would go through the convolutional blocks that try to extract the most important part of data which is actually the pictures generated by the generator or real data. As the Block module is capble of doing down sampling and also up sampling and considering the purpose of discriminator module, the down sampling features is being used here. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W08KLrpPHyaq"
      },
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=4, stride=stride, padding=1, padding_mode='reflect', bias=True),\n",
        "            nn.InstanceNorm2d(out_channels),\n",
        "            nn.LeakyReLU(.2)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_channels=3, features=[64, 128, 256, 512]):\n",
        "        super().__init__()\n",
        "\n",
        "        self.initial = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=in_channels, \n",
        "                out_channels=features[0], \n",
        "                kernel_size=4,\n",
        "                stride=2,\n",
        "                padding=1, \n",
        "                padding_mode='reflect'\n",
        "            ),\n",
        "            nn.LeakyReLU(.2)\n",
        "        )\n",
        "\n",
        "        layers = []\n",
        "        in_channels = features[0]\n",
        "        for feature in features[1:]:\n",
        "            layers.append(Block(in_channels, feature, stride=1 if feature == features[-1] else 2))\n",
        "            in_channels = feature\n",
        "        layers.append(\n",
        "            nn.Conv2d(\n",
        "                in_channels,\n",
        "                 out_channels=1, \n",
        "                 kernel_size=4,\n",
        "                  stride=1, \n",
        "                  padding=1, \n",
        "                  padding_mode='reflect'\n",
        "                  )\n",
        "            )\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.initial(x)\n",
        "        x = torch.sigmoid(self.model(x))\n",
        "        return x"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFgk6OjlHqKv"
      },
      "source": [
        "### Generator Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3l3tA2lc4YHo"
      },
      "source": [
        "The generator module is being implemented in this part. This module gets the pictures from one domain as the input and tries to translate the image to the other domain using three layers of blocks. the first set of blocks are used to down sample the data from the input image to extract the most important features in the image. The process being done in the second layer of this structur is actually analogous to what the fully connected layers do in simpler networks. They get the input resulted from the previous layer and try to pass them through some residual blocks to extract the most important features that can be captures in this stage. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xU0PrrJZkv6J"
      },
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, down_sample=True, use_activation=True, **kwargs):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, padding_mode=\"reflect\", **kwargs) if down_sample else nn.ConvTranspose2d(in_channels, out_channels, **kwargs),\n",
        "            nn.InstanceNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True) if use_activation else nn.Identity()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            ConvBlock(channels, channels, kernel_size=3, padding=1),\n",
        "            ConvBlock(channels, channels, use_activation=False, kernel_size=3, padding=1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.block(x)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, img_channels, num_features = 64, num_residuals=9):\n",
        "        super().__init__()\n",
        "        self.initial = nn.Sequential(\n",
        "            nn.Conv2d(img_channels, num_features, kernel_size=7, stride=1, padding=3, padding_mode=\"reflect\"),\n",
        "            nn.InstanceNorm2d(num_features),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        self.down_blocks = nn.ModuleList(\n",
        "            [\n",
        "                ConvBlock(num_features, num_features*2, kernel_size=3, stride=2, padding=1),\n",
        "                ConvBlock(num_features*2, num_features*4, kernel_size=3, stride=2, padding=1),\n",
        "            ]\n",
        "        )\n",
        "        self.res_blocks = nn.Sequential(\n",
        "            *[ResidualBlock(num_features*4) for _ in range(num_residuals)]\n",
        "        )\n",
        "        self.up_blocks = nn.ModuleList(\n",
        "            [\n",
        "                ConvBlock(num_features*4, num_features*2, down_sample=False, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "                ConvBlock(num_features*2, num_features*1, down_sample=False, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.final = nn.Conv2d(num_features*1, img_channels, kernel_size=7, stride=1, padding=3, padding_mode=\"reflect\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.initial(x)\n",
        "        for layer in self.down_blocks:\n",
        "            x = layer(x)\n",
        "        x = self.res_blocks(x)\n",
        "        for layer in self.up_blocks:\n",
        "            x = layer(x)\n",
        "        x = torch.tanh(self.final(x))\n",
        "        return x"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25a-LnqoHsJA"
      },
      "source": [
        "### DataSet Loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVLxhwfB64B2"
      },
      "source": [
        "The dataset is being loaded from Kaggle and after that the file structure is being modified to suit our purpose for training and using it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "nkF4PB-0Hu0U",
        "outputId": "814e6dd1-33a4-4e3d-9098-580622ad12ab"
      },
      "source": [
        "! pip install -q kaggle\n",
        "from google.colab import files \n",
        "files.upload()\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f496f224-2133-4cbf-9201-eb6087e7d89a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f496f224-2133-4cbf-9201-eb6087e7d89a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLj_zWEyHvWr",
        "outputId": "55b51f46-e0b3-42b8-a877-a236bd7d8884"
      },
      "source": [
        "!kaggle datasets download -d balraj98/monet2photo"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading monet2photo.zip to /content\n",
            " 98% 285M/291M [00:03<00:00, 105MB/s] \n",
            "100% 291M/291M [00:03<00:00, 92.8MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyT1VgGu7bgp"
      },
      "source": [
        "!unzip monet2photo.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02rFKY3K7mmD"
      },
      "source": [
        "!mkdir -p data/train data/test\n",
        "!mv testA data/test/monets\n",
        "!mv testB data/test/photos\n",
        "!mv trainA data/train/monets\n",
        "!mv trainB data/train/photos"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBh4gy9eumFr"
      },
      "source": [
        "### Config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fu_mBP1V7HT1"
      },
      "source": [
        "All the hyper parameters and the constant values are being defined here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssm8Ikw2un2e"
      },
      "source": [
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "TRAIN_DIR = \"data/train\"\n",
        "VAL_DIR = \"data/test\"\n",
        "BATCH_SIZE = 1\n",
        "LEARNING_RATE = 1e-5\n",
        "LAMBDA_IDENTITY = 5\n",
        "SCALE.5\n",
        "TRANSLATE=.5\n",
        "LAMBDA_CYCLE = 10\n",
        "NUM_WORKERS = 2\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "transforms = A.Compose(\n",
        "    [\n",
        "        A.Resize(width=256, height=256),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.Normalize(mean=[TRANSLATE, TRANSLATE, TRANSLATE], std=[SCALE, SCALE, SCALE], max_pixel_value=255),\n",
        "        ToTensorV2(),\n",
        "     ],\n",
        "    additional_targets={\"photo\": \"monet\"},\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyVtlMj7uQGI"
      },
      "source": [
        "### Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zE29Yll7TeU"
      },
      "source": [
        "Functions which are called for saving the weights and check points and also loading them are defined in this section. In addition, the last method defined in this part is for reproducability of the results and seeding all the random variables. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQfsNHqWucux"
      },
      "source": [
        "def seed_everything(seed=42):\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bqi2iTMwldh"
      },
      "source": [
        "class MonetPhotoDataset(Dataset):\n",
        "    def __init__(self, photo_root_dir, monet_root_dir, transform=None):\n",
        "        self.photo_root_dir = photo_root_dir\n",
        "        self.monet_root_dir = monet_root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        self.photo_images = os.listdir(photo_root_dir)\n",
        "        self.monet_images = os.listdir(monet_root_dir)\n",
        "        self.length_dataset = max(len(self.photo_images), len(self.monet_images))\n",
        "        self.photo_len = len(self.photo_images)\n",
        "        self.monet_len = len(self.monet_images)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length_dataset\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        photo_img = self.photo_images[index % self.photo_len]\n",
        "        monet_img = self.monet_images[index % self.monet_len]\n",
        "\n",
        "        monet_path = os.path.join(self.monet_root_dir, monet_img)\n",
        "        photo_path = os.path.join(self.photo_root_dir, photo_img)\n",
        "\n",
        "        monet_img = np.array(Image.open(monet_path).convert(\"RGB\"))\n",
        "        photo_img = np.array(Image.open(photo_path).convert(\"RGB\"))\n",
        "\n",
        "        if self.transform:\n",
        "            augmentations = self.transform(monet=monet_img, photo=photo_img)\n",
        "            monet_img = augmentations[\"monet\"]\n",
        "            photo_img = augmentations[\"photo\"]\n",
        "\n",
        "        return monet_img, photo_img  \n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53mhDuxq0nC1"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtTZTwVHcIUJ"
      },
      "source": [
        "In this part, the train function and the function to call it are defined. In the train function, the photo and the monet are being input to the network and the fake pictures associated with them are generated by the generators. In the next step, these real and fake pictures are fed into the discriminators defined at the last layer of the network to check whether they're real or fake. \n",
        "\n",
        "In the next section, the losses which are related to the generator module are defined. These losses as follows: \n",
        "The first loss which is the regular adversarial loss tries to fool the discriminator by making it accept the fake picture as being a real one. The second loss which is the cycle loss is designated to penalize the model for generating pictures which are too different from the source domain picture. This way, only the features and details not different from the two domains will change and not all the non necessary features and details that may not be changed during the transition from domain A to domain B. Finally, the last loss value's purpuse is to make sure that the generator that should generate pictures in domain D, if given a picture which is already in domain D, will output the input and do not modify it. \n",
        "\n",
        "In the main function, all the necessary modules are instantiated and used to be able to iterate over the dataset by using loader functions and train the model at hand."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikR973fP08go"
      },
      "source": [
        "loss_vector = []\n",
        "\n",
        "def train_fn(disc_photo, disc_monet, gen_monet, gen_photo, loader, opt_disc, opt_gen, l1, mse, d_scaler, g_scaler):\n",
        "    photo_reals = 0\n",
        "    photo_fakes = 0\n",
        "    loop = tqdm(loader, leave=True)\n",
        "    epoch_loss = []\n",
        "\n",
        "    for idx, (monet, photo) in enumerate(loop):\n",
        "        monet = monet.to(DEVICE)\n",
        "        photo = photo.to(DEVICE)\n",
        "\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            fake_photo = gen_photo(monet)\n",
        "            disc_photo_real = disc_photo(photo)\n",
        "            disc_photo_fake = disc_photo(fake_photo.detach())\n",
        "            photo_reals += disc_photo_real.mean().item()\n",
        "            photo_fakes += disc_photo_fake.mean().item()\n",
        "            disc_photo_real_loss = mse(disc_photo_real, torch.ones_like(disc_photo_real))\n",
        "            disc_photo_fake_loss = mse(disc_photo_fake, torch.zeros_like(disc_photo_fake))\n",
        "            disc_photo_loss = disc_photo_real_loss + disc_photo_fake_loss\n",
        "\n",
        "            fake_monet = gen_monet(photo)\n",
        "            disc_monet_real = disc_monet(monet)\n",
        "            disc_monet_fake = disc_monet(fake_monet.detach())\n",
        "            disc_monet_real_loss = mse(disc_monet_real, torch.ones_like(disc_monet_real))\n",
        "            disc_monet_fake_loss = mse(disc_monet_fake, torch.zeros_like(disc_monet_fake))\n",
        "            disc_monet_loss = disc_monet_real_loss + disc_monet_fake_loss\n",
        "\n",
        "        \n",
        "            disc_loss = (disc_photo_loss + disc_monet_loss)/2\n",
        "\n",
        "        opt_disc.zero_grad()\n",
        "        d_scaler.scale(disc_loss).backward()\n",
        "        d_scaler.step(opt_disc)\n",
        "        d_scaler.update()\n",
        "\n",
        "        \n",
        "        with torch.cuda.amp.autocast():\n",
        "            \n",
        "            disc_photo_fake = disc_photo(fake_photo)\n",
        "            disc_monet_fake = disc_monet(fake_monet)\n",
        "            loss_gen_photo = mse(disc_photo_fake, torch.ones_like(disc_photo_fake))\n",
        "            loss_gen_monet = mse(disc_monet_fake, torch.ones_like(disc_monet_fake))\n",
        "\n",
        "            \n",
        "            cycle_monet = gen_monet(fake_photo)\n",
        "            cycle_photo = gen_photo(fake_monet)\n",
        "            cycle_monet_loss = l1(monet, cycle_monet)\n",
        "            cycle_photo_loss = l1(photo, cycle_photo)\n",
        "\n",
        "            \n",
        "            identity_monet = gen_monet(monet)\n",
        "            identity_photo = gen_photo(photo)\n",
        "            identity_monet_loss = l1(monet, identity_monet)\n",
        "            identity_photo_loss = l1(photo, identity_photo)\n",
        "\n",
        "            \n",
        "            G_loss = (\n",
        "                loss_gen_monet\n",
        "                + loss_gen_photo\n",
        "                + cycle_monet_loss * LAMBDA_CYCLE\n",
        "                + cycle_photo_loss * LAMBDA_CYCLE\n",
        "                + identity_photo_loss * LAMBDA_IDENTITY\n",
        "                + identity_monet_loss * LAMBDA_IDENTITY\n",
        "            )\n",
        "        epoch_loss.append(G_loss.item())\n",
        "        loss_vector.append(np.mean(epoch_loss))\n",
        "\n",
        "        opt_gen.zero_grad()\n",
        "        g_scaler.scale(G_loss).backward()\n",
        "        g_scaler.step(opt_gen)\n",
        "        g_scaler.update()\n",
        "\n",
        "        if idx % 200 == 0:\n",
        "            save_image(fake_photo*SCALE+TRANSLATE, f\"saved_images/photo_{idx}.png\")\n",
        "            save_image(fake_monet*SCALE+TRANSLATE, f\"saved_images/monet_{idx}.png\")\n",
        "\n",
        "        loop.set_postfix(H_real=photo_reals/(idx+1), H_fake=photo_fakes/(idx+1))\n",
        "\n",
        "    \n",
        "    print(loss_vector)\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    disc_photo = Discriminator(in_channels=3).to(DEVICE)\n",
        "    disc_monet = Discriminator(in_channels=3).to(DEVICE)\n",
        "    gen_monet = Generator(img_channels=3, num_residuals=9).to(DEVICE)\n",
        "    gen_photo = Generator(img_channels=3, num_residuals=9).to(DEVICE)\n",
        "\n",
        "    L1 = nn.L1Loss()\n",
        "    mse = nn.MSELoss()\n",
        "\n",
        "    opt_disc = optim.Adam(\n",
        "        list(disc_photo.parameters()) + list(disc_monet.parameters()),\n",
        "        lr=LEARNING_RATE,\n",
        "        betas=(0.5, 0.999),\n",
        "    )\n",
        "\n",
        "    opt_gen = optim.Adam(\n",
        "        list(gen_monet.parameters()) + list(gen_photo.parameters()),\n",
        "        lr=LEARNING_RATE,\n",
        "        betas=(0.5, 0.999),\n",
        "    )\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "    dataset = MonetPhotoDataset(\n",
        "        photo_root_dir=TRAIN_DIR+\"/photos\", monet_root_dir=TRAIN_DIR+\"/monets\", transform=transforms\n",
        "    )\n",
        "    val_dataset = MonetPhotoDataset(\n",
        "       photo_root_dir=VAL_DIR+\"/photos\", monet_root_dir=VAL_DIR+\"/monets\", transform=transforms\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=1,\n",
        "        shuffle=False,\n",
        "        pin_memory=True,\n",
        "    )\n",
        "    loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    g_scaler = torch.cuda.amp.GradScaler()\n",
        "    d_scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        train_fn(disc_photo, disc_monet, gen_monet, gen_photo, loader, opt_disc, opt_gen, L1, mse, d_scaler, g_scaler)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zg_aV6QM6e1-"
      },
      "source": [
        "main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "JALbwEqg5syH",
        "outputId": "a4b00b50-7e4a-4db1-c2ea-bee8228ca07c"
      },
      "source": [
        "plt.plot(loss_vector)\n",
        "plt.title('The loss function transition in one epoch')\n",
        "plt.xlabel('iteration')\n",
        "plt.ylabel('loss')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}